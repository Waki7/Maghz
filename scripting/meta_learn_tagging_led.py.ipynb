{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-09-16T00:19:39.031803Z",
     "start_time": "2023-09-16T00:19:38.642268Z"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'logging' from 'huggingface_hub' (/Users/ceyer/miniconda3/envs/Maghz/lib/python3.9/site-packages/huggingface_hub/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 7\u001B[0m\n\u001B[1;32m      5\u001B[0m os\u001B[38;5;241m.\u001B[39mputenv(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPYTORCH_ENABLE_MPS_FALLBACK\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m1\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[0;32m----> 7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mhug\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01msettings\u001B[39;00m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmgz\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mds\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msentence_datasets\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msynthetic_memorization\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m \\\n\u001B[1;32m     10\u001B[0m     SyntheticMemorization\n",
      "File \u001B[0;32m~/miniconda3/envs/Maghz/lib/python3.9/site-packages/transformers/__init__.py:26\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtyping\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m TYPE_CHECKING\n\u001B[1;32m     25\u001B[0m \u001B[38;5;66;03m# Check the dependencies satisfy the minimal versions required.\u001B[39;00m\n\u001B[0;32m---> 26\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m dependency_versions_check\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     28\u001B[0m     OptionalDependencyNotAvailable,\n\u001B[1;32m     29\u001B[0m     _LazyModule,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     42\u001B[0m     logging,\n\u001B[1;32m     43\u001B[0m )\n\u001B[1;32m     46\u001B[0m logger \u001B[38;5;241m=\u001B[39m logging\u001B[38;5;241m.\u001B[39mget_logger(\u001B[38;5;18m__name__\u001B[39m)  \u001B[38;5;66;03m# pylint: disable=invalid-name\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/Maghz/lib/python3.9/site-packages/transformers/dependency_versions_check.py:17\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01msys\u001B[39;00m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdependency_versions_table\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m deps\n\u001B[0;32m---> 17\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mversions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m require_version, require_version_core\n\u001B[1;32m     20\u001B[0m \u001B[38;5;66;03m# define which module versions we always want to check at run time\u001B[39;00m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;66;03m# (usually the ones defined in `install_requires` in setup.py)\u001B[39;00m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;66;03m# order specific notes:\u001B[39;00m\n\u001B[1;32m     24\u001B[0m \u001B[38;5;66;03m# - tqdm must be checked before tokenizers\u001B[39;00m\n\u001B[1;32m     26\u001B[0m pkgs_to_check_at_runtime \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpython tqdm regex requests packaging filelock numpy tokenizers\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39msplit()\n",
      "File \u001B[0;32m~/miniconda3/envs/Maghz/lib/python3.9/site-packages/transformers/utils/__init__.py:30\u001B[0m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mconstants\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD, IMAGENET_STANDARD_MEAN, IMAGENET_STANDARD_STD\n\u001B[1;32m     22\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdoc\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     23\u001B[0m     add_code_sample_docstrings,\n\u001B[1;32m     24\u001B[0m     add_end_docstrings,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     28\u001B[0m     replace_return_docstrings,\n\u001B[1;32m     29\u001B[0m )\n\u001B[0;32m---> 30\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgeneric\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     31\u001B[0m     ContextManagers,\n\u001B[1;32m     32\u001B[0m     ExplicitEnum,\n\u001B[1;32m     33\u001B[0m     ModelOutput,\n\u001B[1;32m     34\u001B[0m     PaddingStrategy,\n\u001B[1;32m     35\u001B[0m     TensorType,\n\u001B[1;32m     36\u001B[0m     add_model_info_to_auto_map,\n\u001B[1;32m     37\u001B[0m     cached_property,\n\u001B[1;32m     38\u001B[0m     can_return_loss,\n\u001B[1;32m     39\u001B[0m     expand_dims,\n\u001B[1;32m     40\u001B[0m     find_labels,\n\u001B[1;32m     41\u001B[0m     flatten_dict,\n\u001B[1;32m     42\u001B[0m     infer_framework,\n\u001B[1;32m     43\u001B[0m     is_jax_tensor,\n\u001B[1;32m     44\u001B[0m     is_numpy_array,\n\u001B[1;32m     45\u001B[0m     is_tensor,\n\u001B[1;32m     46\u001B[0m     is_tf_symbolic_tensor,\n\u001B[1;32m     47\u001B[0m     is_tf_tensor,\n\u001B[1;32m     48\u001B[0m     is_torch_device,\n\u001B[1;32m     49\u001B[0m     is_torch_dtype,\n\u001B[1;32m     50\u001B[0m     is_torch_tensor,\n\u001B[1;32m     51\u001B[0m     reshape,\n\u001B[1;32m     52\u001B[0m     squeeze,\n\u001B[1;32m     53\u001B[0m     strtobool,\n\u001B[1;32m     54\u001B[0m     tensor_size,\n\u001B[1;32m     55\u001B[0m     to_numpy,\n\u001B[1;32m     56\u001B[0m     to_py_obj,\n\u001B[1;32m     57\u001B[0m     transpose,\n\u001B[1;32m     58\u001B[0m     working_or_temp_dir,\n\u001B[1;32m     59\u001B[0m )\n\u001B[1;32m     60\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mhub\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     61\u001B[0m     CLOUDFRONT_DISTRIB_PREFIX,\n\u001B[1;32m     62\u001B[0m     DISABLE_TELEMETRY,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     89\u001B[0m     try_to_load_from_cache,\n\u001B[1;32m     90\u001B[0m )\n\u001B[1;32m     91\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mimport_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     92\u001B[0m     ENV_VARS_TRUE_AND_AUTO_VALUES,\n\u001B[1;32m     93\u001B[0m     ENV_VARS_TRUE_VALUES,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    174\u001B[0m     torch_only_method,\n\u001B[1;32m    175\u001B[0m )\n",
      "File \u001B[0;32m~/miniconda3/envs/Maghz/lib/python3.9/site-packages/transformers/utils/generic.py:29\u001B[0m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtyping\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Any, ContextManager, List, Tuple\n\u001B[1;32m     27\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[0;32m---> 29\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mimport_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m is_flax_available, is_tf_available, is_torch_available, is_torch_fx_proxy\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_flax_available():\n\u001B[1;32m     33\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mjax\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mjnp\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/Maghz/lib/python3.9/site-packages/transformers/utils/import_utils.py:33\u001B[0m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtyping\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Any, Tuple, Union\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpackaging\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m version\n\u001B[0;32m---> 33\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m logging\n\u001B[1;32m     34\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mversions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m importlib_metadata\n\u001B[1;32m     37\u001B[0m logger \u001B[38;5;241m=\u001B[39m logging\u001B[38;5;241m.\u001B[39mget_logger(\u001B[38;5;18m__name__\u001B[39m)  \u001B[38;5;66;03m# pylint: disable=invalid-name\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/Maghz/lib/python3.9/site-packages/transformers/utils/logging.py:35\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mlogging\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     24\u001B[0m     CRITICAL,  \u001B[38;5;66;03m# NOQA\u001B[39;00m\n\u001B[1;32m     25\u001B[0m     DEBUG,  \u001B[38;5;66;03m# NOQA\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     31\u001B[0m     WARNING,  \u001B[38;5;66;03m# NOQA\u001B[39;00m\n\u001B[1;32m     32\u001B[0m )\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtyping\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Optional\n\u001B[0;32m---> 35\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mhuggingface_hub\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mhf_hub_utils\u001B[39;00m\n\u001B[1;32m     36\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtqdm\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m auto \u001B[38;5;28;01mas\u001B[39;00m tqdm_lib\n\u001B[1;32m     39\u001B[0m _lock \u001B[38;5;241m=\u001B[39m threading\u001B[38;5;241m.\u001B[39mLock()\n",
      "File \u001B[0;32m~/miniconda3/envs/Maghz/lib/python3.9/site-packages/huggingface_hub/utils/__init__.py:91\u001B[0m\n\u001B[1;32m     78\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_validators\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     79\u001B[0m     HFValidationError,\n\u001B[1;32m     80\u001B[0m     smoothly_deprecate_use_auth_token,\n\u001B[1;32m     81\u001B[0m     validate_hf_hub_args,\n\u001B[1;32m     82\u001B[0m     validate_repo_id,\n\u001B[1;32m     83\u001B[0m )\n\u001B[1;32m     84\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtqdm\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     85\u001B[0m     are_progress_bars_disabled,\n\u001B[1;32m     86\u001B[0m     disable_progress_bars,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     89\u001B[0m     tqdm_stream_file,\n\u001B[1;32m     90\u001B[0m )\n\u001B[0;32m---> 91\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_telemetry\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m send_telemetry\n",
      "File \u001B[0;32m~/miniconda3/envs/Maghz/lib/python3.9/site-packages/huggingface_hub/utils/_telemetry.py:6\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtyping\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Dict, Optional, Union\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01murllib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mparse\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m quote\n\u001B[0;32m----> 6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m constants, logging\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m build_hf_headers, get_session, hf_raise_for_status\n\u001B[1;32m     10\u001B[0m logger \u001B[38;5;241m=\u001B[39m logging\u001B[38;5;241m.\u001B[39mget_logger(\u001B[38;5;18m__name__\u001B[39m)\n",
      "\u001B[0;31mImportError\u001B[0m: cannot import name 'logging' from 'huggingface_hub' (/Users/ceyer/miniconda3/envs/Maghz/lib/python3.9/site-packages/huggingface_hub/__init__.py)"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "# from mgz.models.nlp.bart_interface import BARTHubInterface\n",
    "import os\n",
    "\n",
    "os.putenv(\"PYTORCH_ENABLE_MPS_FALLBACK\", \"1\")\n",
    "import torch\n",
    "import transformers as hug\n",
    "import mgz.settings as settings\n",
    "from mgz.ds.sentence_datasets.synthetic_memorization import \\\n",
    "    SyntheticMemorization\n",
    "from mgz.models.nlp.led import LEDForBinaryTagging\n",
    "import logging\n",
    "\n",
    "from mgz.ds.sentence_datasets.aus_legal_case_reports import \\\n",
    "    AusCaseReportsToTagGrouped\n",
    "from mgz.model_running.learning_ops import LabelSmoothing\n",
    "from mgz.model_running import TaggingRoutine\n",
    "from mgz.version_control import ModelEdge, ModelNode\n",
    "\n",
    "'''\n",
    "input_ids tensor([[    0, 31414,   232,  1437,     2,     2]])\n",
    "attention_mask None\n",
    "attn_weights torch.Size([16, 6, 6])\n",
    "attn_probs torch.Size([16, 6, 6])\n",
    "'''\n",
    "\n",
    "\n",
    "def dataset_memorization():\n",
    "    return SyntheticMemorization(128, 128, 128, 1000, 1), SyntheticMemorization(\n",
    "        128, 128, 128, 1000, 1)\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "batch_size = 4\n",
    "# Initializing a BART facebook/bart-large style configuration\n",
    "# model_name = \"facebook/bart-base\"\n",
    "# model_name = 'allenai/bart-large-multi_lexsum-long-tiny'\n",
    "# model_name = 'allenai/bart-large-multi_lexsum-long-short'\n",
    "model_name = 'allenai/led-base-16384-multi_lexsum-source-long'\n",
    "print('... loading model and tokenizer')\n",
    "with torch.cuda.amp.autocast():\n",
    "    model, tokenizer = LEDForBinaryTagging.from_pretrained(\n",
    "        model_name,\n",
    "        model_name)\n",
    "    model.to(settings.DEVICE)\n",
    "    cfg: hug.LEDConfig = model.config\n",
    "    print(cfg.attention_window)\n",
    "    model.train()\n",
    "\n",
    "    dataset = AusCaseReportsToTagGrouped(tokenizer,\n",
    "                                         cfg.max_position_embeddings)\n",
    "    routine = TaggingRoutine()\n",
    "    model_node = ModelNode(model, tokenizer)\n",
    "    loss_fn = LabelSmoothing(\n",
    "        n_cls=dataset.tgt_vocab_len(), padding_idx=tokenizer.pad_token_id,\n",
    "        smoothing=0.1\n",
    "    ).to(settings.DEVICE)\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(), lr=.00001, betas=(0.9, 0.98),\n",
    "        eps=1e-4\n",
    "    )\n",
    "    train_transition_edge = ModelEdge(model_node, loss_fn, optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with torch.cuda.amp.autocast():\n",
    "    routine.train(model_node=model_node, ds=dataset,\n",
    "                  model_edge=train_transition_edge, batch_size=batch_size,\n",
    "                  device=settings.DEVICE, distributed=False,\n",
    "                  turn_off_shuffle=True)\n",
    "\n",
    "    torch.cuda.empty_cache()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
